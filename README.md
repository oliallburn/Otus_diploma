# Выпускной проект по курсу OTUS Data Engineer
# Тема: обработка и отслеживание данных о телепросмотре
# ..или "больше Data меньше Engineer"
### Описание задачи:
В нашу воображаемую мини-систему регулярно некоторым образом приходят данные о том, как долго и что именно смотрят на экранах ТВ субъекты исследования. Задача состоит в создании автоматизированной системы обработки и тестирования данных, а также их наглядной визуализции. 

### Основную задачу можно разделить на части:
 - Развертывание инфраструктуры посредством Docker
 - Настройка Apache Airflow для управления процессом загрузки входящих пакетов в БД и обработки данных
 - Использование Postgres для хранения данных 
 - Реализация Data Build Tool для трансформации и тестирования данных
 - Создание дашборда в Grafana

### Вспомогательное ПО:
  VS code, DBeaver, Git + github

### Входящие пакеты:
На вход нашей игрушечной системе подаются два .csv файла:
- Интервалы просмотра субъектами исследования некоторых id-сущностей
- Словарь с расшифровкой связи id / телеканал

### Docker:
Инструкция по установке Docker на рабочую машину есть здесь: https://docs.docker.com/engine/install/

В корневой директории в репозитории содержатся файлы: 
- Dockerfile - инструкции, необходимые для создания окружения
- docker-compose.yml - инструкции, необходимые для запуска и настройки сервисов
- requirements.txt - инструкции по установке дополнительных зависимостей (dbt)

Сборка и запуск контейнера осуществляется следующими командами
```sh
docker-compose build
docker-compose up
```

### Airflow:
<http://0.0.0.0:8080/admin/>

Оркестрация реализована при помощи Airflow. Он управляет запуском пайплайна, который
 - task_load_files_into_db: загружает данные в PostgreSQL (PythonOperator, SQLalchemy)
 - task_transform_data_in_db: преобразовывает данные для результирующей витрины (BashOperator, dbt)
 - task_test_data_in_db: тестирует данные на отсутствие дублей и null (BashOperator, dbt)

### Data Build Tool:
Фреймворк DBT используется как непосредственно для трансформации, так и для тестирования механической корректности данных:
- трансформация (dbt run)  - перекладывание в staging слой, склеивание таблиц и создание результирующей витрины данных с топом телеканалов по вкладу в совокупное время просмотра ТВ. Финальный запрос: 
```sql
select 
	channel_name,
	sum(duration) as totalsek,
	sum(duration) * 100.0 / sum(sum(duration)) over () as percentage
from {{ ref('view_with_ch') }}
group by channel_name
order by totalsek desc
```
- тестирование (dbt test)  - проверка на отсутсвие null в поле с длительностью просмотра и уникальность айдишек телеканалов
```yaml
version: 2

sources:
  - name: source
    schema: public
    tables:
      - name: resp_view
        columns:
          - name: duration
            tests:
              - not_null
      - name: ch_id
        columns:
          - name: mediapackageid
            tests:
              - unique
```

### Grafana:
<http://0.0.0.0:9000/>

После выполнения пайплайна результирующие данные оказываются в PostgreSQL. Чтобы пощупать данные можно подключить соединение в DBeaver: jdbc:postgresql://localhost:5432/airflow, credentials: airflow/airflow
Используем Grafana для элементарной визуализации. Обычно Grafana используется для мониторинга процессов, а не как классический дашборд, но она слишком удобная и симпатичная, чтобы от него отказаться для нашей простой задачи.
Для подкючения источника возможно понадобиться узнать docker host IP следующим образом:
```bash
ip add
```
В итоге используем 172.18.0.1:5432 как host и делаем столбчатую таблицу.

### Дальнейшее развитие:
Сделать систему менее кукольной, добавив, как минимум, получение входящих пакетов из Kafka - в текущей системе мы забираем файлы из папки, в которой они оказываются волшебным образом. И вместо обычной файловой системы использовать Hadoop и Spark, конечно же. Но оставим это дата-инженерам :)

